{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9768b146",
   "metadata": {},
   "source": [
    "# Credit Risk Prediction: Data Cleaning & Preprocessing\n",
    "\n",
    "This notebook is part of a larger project exploring machine learning approaches to **credit risk prediction** using real-world LendingClub loan data (2007–2018). The goal is to build predictive models that can assess the likelihood of a loan default based on borrower attributes and financial history.\n",
    "\n",
    "> The cleaned dataset produced here will be used in subsequent notebooks to train and evaluate various machine learning models including logistic regression, decision trees, random forests, and gradient boosting.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2228ad3",
   "metadata": {},
   "source": [
    "## Load the LendingClub Dataset\n",
    "\n",
    "Importing the LendingClub \"Accepted Loans (2007–2018Q4)\" dataset, which contains millions of rows and a wide variety of loan-related features. Since it's a large file, we used `low_memory=False` to ensure all data types are properly inferred without memory fragmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39c9d516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>...</th>\n",
       "      <th>hardship_payoff_balance_amount</th>\n",
       "      <th>hardship_last_payment_amount</th>\n",
       "      <th>disbursement_method</th>\n",
       "      <th>debt_settlement_flag</th>\n",
       "      <th>debt_settlement_flag_date</th>\n",
       "      <th>settlement_status</th>\n",
       "      <th>settlement_date</th>\n",
       "      <th>settlement_amount</th>\n",
       "      <th>settlement_percentage</th>\n",
       "      <th>settlement_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68407277</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.99</td>\n",
       "      <td>123.03</td>\n",
       "      <td>C</td>\n",
       "      <td>C4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68355089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24700.0</td>\n",
       "      <td>24700.0</td>\n",
       "      <td>24700.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>11.99</td>\n",
       "      <td>820.28</td>\n",
       "      <td>C</td>\n",
       "      <td>C1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68341763</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>10.78</td>\n",
       "      <td>432.66</td>\n",
       "      <td>B</td>\n",
       "      <td>B4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66310712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>14.85</td>\n",
       "      <td>829.90</td>\n",
       "      <td>C</td>\n",
       "      <td>C5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68476807</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>22.45</td>\n",
       "      <td>289.91</td>\n",
       "      <td>F</td>\n",
       "      <td>F1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  member_id  loan_amnt  funded_amnt  funded_amnt_inv        term  \\\n",
       "0  68407277        NaN     3600.0       3600.0           3600.0   36 months   \n",
       "1  68355089        NaN    24700.0      24700.0          24700.0   36 months   \n",
       "2  68341763        NaN    20000.0      20000.0          20000.0   60 months   \n",
       "3  66310712        NaN    35000.0      35000.0          35000.0   60 months   \n",
       "4  68476807        NaN    10400.0      10400.0          10400.0   60 months   \n",
       "\n",
       "   int_rate  installment grade sub_grade  ... hardship_payoff_balance_amount  \\\n",
       "0     13.99       123.03     C        C4  ...                            NaN   \n",
       "1     11.99       820.28     C        C1  ...                            NaN   \n",
       "2     10.78       432.66     B        B4  ...                            NaN   \n",
       "3     14.85       829.90     C        C5  ...                            NaN   \n",
       "4     22.45       289.91     F        F1  ...                            NaN   \n",
       "\n",
       "  hardship_last_payment_amount disbursement_method  debt_settlement_flag  \\\n",
       "0                          NaN                Cash                     N   \n",
       "1                          NaN                Cash                     N   \n",
       "2                          NaN                Cash                     N   \n",
       "3                          NaN                Cash                     N   \n",
       "4                          NaN                Cash                     N   \n",
       "\n",
       "  debt_settlement_flag_date settlement_status settlement_date  \\\n",
       "0                       NaN               NaN             NaN   \n",
       "1                       NaN               NaN             NaN   \n",
       "2                       NaN               NaN             NaN   \n",
       "3                       NaN               NaN             NaN   \n",
       "4                       NaN               NaN             NaN   \n",
       "\n",
       "  settlement_amount settlement_percentage settlement_term  \n",
       "0               NaN                   NaN             NaN  \n",
       "1               NaN                   NaN             NaN  \n",
       "2               NaN                   NaN             NaN  \n",
       "3               NaN                   NaN             NaN  \n",
       "4               NaN                   NaN             NaN  \n",
       "\n",
       "[5 rows x 151 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data (this might take a moment – it's large)\n",
    "df = pd.read_csv('../data/accepted_2007_to_2018Q4.csv', low_memory=False)\n",
    "\n",
    "# Show first rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de92b86f",
   "metadata": {},
   "source": [
    "## Filter for Fully Paid and Charged Off Loans\n",
    "\n",
    "The `loan_status` column contains many categories like \"Current\", \"Late\", or \"In Grace Period\" that don’t reflect final outcomes. To create a meaningful binary classification problem, we filtered the dataset to keep only rows where `loan_status` is either:\n",
    "- `\"Fully Paid\"` (loan repaid successfully)\n",
    "- `\"Charged Off\"` (loan defaulted)\n",
    "\n",
    "This simplifies the target variable and ensures clarity in modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c7f6f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loan_status\n",
       "Fully Paid                                             1076751\n",
       "Current                                                 878317\n",
       "Charged Off                                             268559\n",
       "Late (31-120 days)                                       21467\n",
       "In Grace Period                                           8436\n",
       "Late (16-30 days)                                         4349\n",
       "Does not meet the credit policy. Status:Fully Paid        1988\n",
       "Does not meet the credit policy. Status:Charged Off        761\n",
       "Default                                                     40\n",
       "NaN                                                         33\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['loan_status'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcca67e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['loan_status'].isin(['Fully Paid', 'Charged Off'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074b2c81",
   "metadata": {},
   "source": [
    "## Create a Binary Target Column (`default`)\n",
    "\n",
    "We created a new column named `default` to serve as the target for classification:\n",
    "- `1` for \"Charged Off\" loans (defaulted)\n",
    "- `0` for \"Fully Paid\" loans (repaid)\n",
    "\n",
    "This conversion allows us to model the problem as a binary classification task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3396ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "default\n",
       "0    0.800374\n",
       "1    0.199626\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the binary target\n",
    "df['default'] = df['loan_status'].apply(lambda x: 1 if x == 'Charged Off' else 0)\n",
    "\n",
    "# Check new label distribution\n",
    "df['default'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c317f039",
   "metadata": {},
   "source": [
    "## Column Removal: Preventing Data Leakage and Redundancy\n",
    "\n",
    "To ensure our model is both realistic and robust, we carefully removed several columns from the dataset that fall into the following different categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39cdb9dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'member_id',\n",
       " 'loan_amnt',\n",
       " 'funded_amnt',\n",
       " 'funded_amnt_inv',\n",
       " 'term',\n",
       " 'int_rate',\n",
       " 'installment',\n",
       " 'grade',\n",
       " 'sub_grade',\n",
       " 'emp_title',\n",
       " 'emp_length',\n",
       " 'home_ownership',\n",
       " 'annual_inc',\n",
       " 'verification_status',\n",
       " 'issue_d',\n",
       " 'loan_status',\n",
       " 'pymnt_plan',\n",
       " 'url',\n",
       " 'desc',\n",
       " 'purpose',\n",
       " 'title',\n",
       " 'zip_code',\n",
       " 'addr_state',\n",
       " 'dti',\n",
       " 'delinq_2yrs',\n",
       " 'earliest_cr_line',\n",
       " 'fico_range_low',\n",
       " 'fico_range_high',\n",
       " 'inq_last_6mths',\n",
       " 'mths_since_last_delinq',\n",
       " 'mths_since_last_record',\n",
       " 'open_acc',\n",
       " 'pub_rec',\n",
       " 'revol_bal',\n",
       " 'revol_util',\n",
       " 'total_acc',\n",
       " 'initial_list_status',\n",
       " 'out_prncp',\n",
       " 'out_prncp_inv',\n",
       " 'total_pymnt',\n",
       " 'total_pymnt_inv',\n",
       " 'total_rec_prncp',\n",
       " 'total_rec_int',\n",
       " 'total_rec_late_fee',\n",
       " 'recoveries',\n",
       " 'collection_recovery_fee',\n",
       " 'last_pymnt_d',\n",
       " 'last_pymnt_amnt',\n",
       " 'next_pymnt_d',\n",
       " 'last_credit_pull_d',\n",
       " 'last_fico_range_high',\n",
       " 'last_fico_range_low',\n",
       " 'collections_12_mths_ex_med',\n",
       " 'mths_since_last_major_derog',\n",
       " 'policy_code',\n",
       " 'application_type',\n",
       " 'annual_inc_joint',\n",
       " 'dti_joint',\n",
       " 'verification_status_joint',\n",
       " 'acc_now_delinq',\n",
       " 'tot_coll_amt',\n",
       " 'tot_cur_bal',\n",
       " 'open_acc_6m',\n",
       " 'open_act_il',\n",
       " 'open_il_12m',\n",
       " 'open_il_24m',\n",
       " 'mths_since_rcnt_il',\n",
       " 'total_bal_il',\n",
       " 'il_util',\n",
       " 'open_rv_12m',\n",
       " 'open_rv_24m',\n",
       " 'max_bal_bc',\n",
       " 'all_util',\n",
       " 'total_rev_hi_lim',\n",
       " 'inq_fi',\n",
       " 'total_cu_tl',\n",
       " 'inq_last_12m',\n",
       " 'acc_open_past_24mths',\n",
       " 'avg_cur_bal',\n",
       " 'bc_open_to_buy',\n",
       " 'bc_util',\n",
       " 'chargeoff_within_12_mths',\n",
       " 'delinq_amnt',\n",
       " 'mo_sin_old_il_acct',\n",
       " 'mo_sin_old_rev_tl_op',\n",
       " 'mo_sin_rcnt_rev_tl_op',\n",
       " 'mo_sin_rcnt_tl',\n",
       " 'mort_acc',\n",
       " 'mths_since_recent_bc',\n",
       " 'mths_since_recent_bc_dlq',\n",
       " 'mths_since_recent_inq',\n",
       " 'mths_since_recent_revol_delinq',\n",
       " 'num_accts_ever_120_pd',\n",
       " 'num_actv_bc_tl',\n",
       " 'num_actv_rev_tl',\n",
       " 'num_bc_sats',\n",
       " 'num_bc_tl',\n",
       " 'num_il_tl',\n",
       " 'num_op_rev_tl',\n",
       " 'num_rev_accts',\n",
       " 'num_rev_tl_bal_gt_0',\n",
       " 'num_sats',\n",
       " 'num_tl_120dpd_2m',\n",
       " 'num_tl_30dpd',\n",
       " 'num_tl_90g_dpd_24m',\n",
       " 'num_tl_op_past_12m',\n",
       " 'pct_tl_nvr_dlq',\n",
       " 'percent_bc_gt_75',\n",
       " 'pub_rec_bankruptcies',\n",
       " 'tax_liens',\n",
       " 'tot_hi_cred_lim',\n",
       " 'total_bal_ex_mort',\n",
       " 'total_bc_limit',\n",
       " 'total_il_high_credit_limit',\n",
       " 'revol_bal_joint',\n",
       " 'sec_app_fico_range_low',\n",
       " 'sec_app_fico_range_high',\n",
       " 'sec_app_earliest_cr_line',\n",
       " 'sec_app_inq_last_6mths',\n",
       " 'sec_app_mort_acc',\n",
       " 'sec_app_open_acc',\n",
       " 'sec_app_revol_util',\n",
       " 'sec_app_open_act_il',\n",
       " 'sec_app_num_rev_accts',\n",
       " 'sec_app_chargeoff_within_12_mths',\n",
       " 'sec_app_collections_12_mths_ex_med',\n",
       " 'sec_app_mths_since_last_major_derog',\n",
       " 'hardship_flag',\n",
       " 'hardship_type',\n",
       " 'hardship_reason',\n",
       " 'hardship_status',\n",
       " 'deferral_term',\n",
       " 'hardship_amount',\n",
       " 'hardship_start_date',\n",
       " 'hardship_end_date',\n",
       " 'payment_plan_start_date',\n",
       " 'hardship_length',\n",
       " 'hardship_dpd',\n",
       " 'hardship_loan_status',\n",
       " 'orig_projected_additional_accrued_interest',\n",
       " 'hardship_payoff_balance_amount',\n",
       " 'hardship_last_payment_amount',\n",
       " 'disbursement_method',\n",
       " 'debt_settlement_flag',\n",
       " 'debt_settlement_flag_date',\n",
       " 'settlement_status',\n",
       " 'settlement_date',\n",
       " 'settlement_amount',\n",
       " 'settlement_percentage',\n",
       " 'settlement_term',\n",
       " 'default']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d43d963",
   "metadata": {},
   "source": [
    "### 1. Leakage Columns\n",
    "These columns contain information that would **not be available at the time of loan issuance**, such as payment history, recoveries, or post-loan credit scores. Including them would result in **data leakage**, leading to overly optimistic model performance. Examples include:\n",
    "- Total payments and principal recovered (`total_pymnt`, `recoveries`)\n",
    "- Last and next payment dates (`last_pymnt_d`, `next_pymnt_d`)\n",
    "- Post-loan FICO scores (`last_fico_range_low`, `last_fico_range_high`)\n",
    "- Hardship and debt settlement statuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cd792b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "leakage_cols = [\n",
    "    'loan_status',  # already used to create 'default'\n",
    "    \n",
    "    # Post-issuance payment/recovery info\n",
    "    'out_prncp', 'out_prncp_inv',\n",
    "    'total_pymnt', 'total_pymnt_inv',\n",
    "    'total_rec_prncp', 'total_rec_int', 'total_rec_late_fee',\n",
    "    'recoveries', 'collection_recovery_fee',\n",
    "    \n",
    "    # Post-loan date fields\n",
    "    'last_pymnt_d', 'last_pymnt_amnt',\n",
    "    'next_pymnt_d', 'last_credit_pull_d',\n",
    "\n",
    "    # Hardship-related (only happens if borrower struggles later)\n",
    "    'hardship_flag', 'hardship_type', 'hardship_reason',\n",
    "    'hardship_status', 'deferral_term', 'hardship_amount',\n",
    "    'hardship_start_date', 'hardship_end_date',\n",
    "    'payment_plan_start_date', 'hardship_length',\n",
    "    'hardship_dpd', 'hardship_loan_status',\n",
    "    'orig_projected_additional_accrued_interest',\n",
    "    'hardship_payoff_balance_amount',\n",
    "    'hardship_last_payment_amount',\n",
    "\n",
    "    # Debt settlement information\n",
    "    'debt_settlement_flag', 'debt_settlement_flag_date',\n",
    "    'settlement_status', 'settlement_date',\n",
    "    'settlement_amount', 'settlement_percentage',\n",
    "    'settlement_term',\n",
    "\n",
    "    # Post-issuance FICO scores\n",
    "    'last_fico_range_low', 'last_fico_range_high'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755f02e5",
   "metadata": {},
   "source": [
    "### 2. Non-Predictive Metadata\n",
    "These fields are either:\n",
    "- Unique identifiers (`id`, `member_id`)\n",
    "- Free-text or noisy fields (`emp_title`, `desc`)\n",
    "- Redundant or uninformative (`zip_code`, `pymnt_plan`, `policy_code`)\n",
    "\n",
    "These do not contribute meaningful signal and may increase noise or dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72eddd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_predictive_cols = [\n",
    "    'id', 'member_id',          # Unique identifiers\n",
    "    'emp_title', 'url', 'desc', # Unstructured text fields\n",
    "    'title',                    # Often duplicates purpose\n",
    "    'zip_code', 'addr_state',   # Hard to generalize or engineer\n",
    "    'issue_d',                  # Loan issuance date\n",
    "    'pymnt_plan',               # Almost always 'n'\n",
    "    'disbursement_method',      # Nearly always one value\n",
    "    'policy_code'               # Constant = 1\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ded8275",
   "metadata": {},
   "source": [
    "### 3. Second Applicant Information\n",
    "Our model does not distinguish between individual and joint applications. Therefore, we removed all features related to **secondary applicants** (`sec_app_*`), which are frequently missing and not applicable to most loans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ada0050",
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_app_cols = [\n",
    "    'sec_app_fico_range_low', 'sec_app_fico_range_high',\n",
    "    'sec_app_earliest_cr_line', 'sec_app_inq_last_6mths',\n",
    "    'sec_app_mort_acc', 'sec_app_open_acc',\n",
    "    'sec_app_revol_util', 'sec_app_open_act_il',\n",
    "    'sec_app_num_rev_accts', 'sec_app_chargeoff_within_12_mths',\n",
    "    'sec_app_collections_12_mths_ex_med',\n",
    "    'sec_app_mths_since_last_major_derog'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff602192",
   "metadata": {},
   "source": [
    "We combined all of the above into one list and removed them from the dataset using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aafe70e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine both drop lists\n",
    "cols_to_drop = leakage_cols + non_predictive_cols + sec_app_cols\n",
    "\n",
    "# Drop\n",
    "df = df.drop(columns=cols_to_drop, errors='ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1eac3cb",
   "metadata": {},
   "source": [
    "The remaining columns are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1dc338fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loan_amnt',\n",
       " 'funded_amnt',\n",
       " 'funded_amnt_inv',\n",
       " 'term',\n",
       " 'int_rate',\n",
       " 'installment',\n",
       " 'grade',\n",
       " 'sub_grade',\n",
       " 'emp_length',\n",
       " 'home_ownership',\n",
       " 'annual_inc',\n",
       " 'verification_status',\n",
       " 'purpose',\n",
       " 'dti',\n",
       " 'delinq_2yrs',\n",
       " 'earliest_cr_line',\n",
       " 'fico_range_low',\n",
       " 'fico_range_high',\n",
       " 'inq_last_6mths',\n",
       " 'mths_since_last_delinq',\n",
       " 'mths_since_last_record',\n",
       " 'open_acc',\n",
       " 'pub_rec',\n",
       " 'revol_bal',\n",
       " 'revol_util',\n",
       " 'total_acc',\n",
       " 'initial_list_status',\n",
       " 'collections_12_mths_ex_med',\n",
       " 'mths_since_last_major_derog',\n",
       " 'application_type',\n",
       " 'annual_inc_joint',\n",
       " 'dti_joint',\n",
       " 'verification_status_joint',\n",
       " 'acc_now_delinq',\n",
       " 'tot_coll_amt',\n",
       " 'tot_cur_bal',\n",
       " 'open_acc_6m',\n",
       " 'open_act_il',\n",
       " 'open_il_12m',\n",
       " 'open_il_24m',\n",
       " 'mths_since_rcnt_il',\n",
       " 'total_bal_il',\n",
       " 'il_util',\n",
       " 'open_rv_12m',\n",
       " 'open_rv_24m',\n",
       " 'max_bal_bc',\n",
       " 'all_util',\n",
       " 'total_rev_hi_lim',\n",
       " 'inq_fi',\n",
       " 'total_cu_tl',\n",
       " 'inq_last_12m',\n",
       " 'acc_open_past_24mths',\n",
       " 'avg_cur_bal',\n",
       " 'bc_open_to_buy',\n",
       " 'bc_util',\n",
       " 'chargeoff_within_12_mths',\n",
       " 'delinq_amnt',\n",
       " 'mo_sin_old_il_acct',\n",
       " 'mo_sin_old_rev_tl_op',\n",
       " 'mo_sin_rcnt_rev_tl_op',\n",
       " 'mo_sin_rcnt_tl',\n",
       " 'mort_acc',\n",
       " 'mths_since_recent_bc',\n",
       " 'mths_since_recent_bc_dlq',\n",
       " 'mths_since_recent_inq',\n",
       " 'mths_since_recent_revol_delinq',\n",
       " 'num_accts_ever_120_pd',\n",
       " 'num_actv_bc_tl',\n",
       " 'num_actv_rev_tl',\n",
       " 'num_bc_sats',\n",
       " 'num_bc_tl',\n",
       " 'num_il_tl',\n",
       " 'num_op_rev_tl',\n",
       " 'num_rev_accts',\n",
       " 'num_rev_tl_bal_gt_0',\n",
       " 'num_sats',\n",
       " 'num_tl_120dpd_2m',\n",
       " 'num_tl_30dpd',\n",
       " 'num_tl_90g_dpd_24m',\n",
       " 'num_tl_op_past_12m',\n",
       " 'pct_tl_nvr_dlq',\n",
       " 'percent_bc_gt_75',\n",
       " 'pub_rec_bankruptcies',\n",
       " 'tax_liens',\n",
       " 'tot_hi_cred_lim',\n",
       " 'total_bal_ex_mort',\n",
       " 'total_bc_limit',\n",
       " 'total_il_high_credit_limit',\n",
       " 'revol_bal_joint',\n",
       " 'default']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe25949",
   "metadata": {},
   "source": [
    "## Handling Missing Values\n",
    "\n",
    "Dealing with missing data is a critical step in preparing the dataset for machine learning. In this section, we assess and handle missing values to ensure a clean, model-ready dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f05924",
   "metadata": {},
   "source": [
    "### Step 1: Identify Columns with Missing Values\n",
    "\n",
    "We begin by calculating the percentage of missing values in each column, sorted in descending order. This gives us insight into which columns have the most missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed91cff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "revol_bal_joint                   0.986153\n",
       "verification_status_joint         0.980975\n",
       "dti_joint                         0.980824\n",
       "annual_inc_joint                  0.980822\n",
       "mths_since_last_record            0.830110\n",
       "mths_since_recent_bc_dlq          0.762865\n",
       "mths_since_last_major_derog       0.737049\n",
       "mths_since_recent_revol_delinq    0.665533\n",
       "il_util                           0.654343\n",
       "mths_since_rcnt_il                0.610958\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find % of missing values for each column\n",
    "missing = df.isnull().mean().sort_values(ascending=False)\n",
    "missing.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bae5c4",
   "metadata": {},
   "source": [
    "### Step 2: Drop Columns with >30% Missing Values\n",
    "\n",
    "Features with more than 30% missing values are dropped. These columns are likely too incomplete to provide reliable signal and may introduce noise if imputed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35b79753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['revol_bal_joint', 'verification_status_joint', 'dti_joint',\n",
      "       'annual_inc_joint', 'mths_since_last_record',\n",
      "       'mths_since_recent_bc_dlq', 'mths_since_last_major_derog',\n",
      "       'mths_since_recent_revol_delinq', 'il_util', 'mths_since_rcnt_il',\n",
      "       'all_util', 'total_cu_tl', 'open_acc_6m', 'inq_last_12m', 'inq_fi',\n",
      "       'open_rv_24m', 'open_rv_12m', 'total_bal_il', 'open_il_24m',\n",
      "       'open_il_12m', 'open_act_il', 'max_bal_bc', 'mths_since_last_delinq'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.3\n",
    "cols_to_drop = missing[missing > threshold].index\n",
    "df = df.drop(columns=cols_to_drop)\n",
    "print(cols_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c2bffa",
   "metadata": {},
   "source": [
    "### Step 3: Fill Missing Numeric Values with Median\n",
    "\n",
    "For numeric features, we impute missing values using the median. The median is robust to outliers, which makes it suitable for skewed financial variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e8b8d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in missing values\n",
    "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b90223",
   "metadata": {},
   "source": [
    "### Step 4: Fill Missing Categorical Values with Mode\n",
    "\n",
    "For categorical features, we impute missing values using the most frequent value (mode) to preserve the dominant category and ensure one-hot encoding works correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80e440de",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "df[categorical_cols] = df[categorical_cols].fillna(df[categorical_cols].mode().iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae35766",
   "metadata": {},
   "source": [
    "### Step 5: Final Check for Missing Values\n",
    "\n",
    "We now verify that all missing values have been handled. The result should be zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45bb47e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6460bb9d",
   "metadata": {},
   "source": [
    "## Encoding Categorical Features\n",
    "\n",
    "Most machine learning models require all input features to be numeric. However, many of the features in our dataset are categorical, such as `home_ownership`, `purpose`, or `verification_status`.\n",
    "\n",
    "To make these categorical variables usable, we apply **one-hot encoding**, which transforms each category into a separate binary column (0 or 1). This allows the model to treat each category as an independent feature without introducing false ordinal relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60812c0",
   "metadata": {},
   "source": [
    "### Step 1: One-Hot Encode Categorical Variables\n",
    "\n",
    "We use `pd.get_dummies()` to one-hot encode all non-numeric columns. The `drop_first=True` parameter avoids multicollinearity by dropping the first category from each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14d903e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all non-numeric columns and one-hot encode them\n",
    "df_encoded = pd.get_dummies(df, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10113369",
   "metadata": {},
   "source": [
    "### Step 2: Verify All Features Are Now Numeric\n",
    "\n",
    "After encoding, we check the data types of all columns to ensure everything is now numeric and ready for model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d026f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bool       811\n",
       "float64     56\n",
       "int64        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3871749",
   "metadata": {},
   "source": [
    "### Step 3: Final Check for Unencoded Categorical Columns\n",
    "\n",
    "Even after one-hot encoding, it's good practice to confirm that no `object` (i.e., string-based) columns remain in the dataset. This step helps catch any features that were missed or unexpectedly formatted.\n",
    "\n",
    "If the output is an empty list, it means all features are successfully numeric and the dataset is ready for scaling and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "455244b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded.select_dtypes(include='object').columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9efe6fc",
   "metadata": {},
   "source": [
    "## Splitting Features and Target\n",
    "\n",
    "Before we can scale the data or train any models, we need to separate our dataset into:\n",
    "- **Features (`X`)**: All the independent variables that the model will use to make predictions.\n",
    "- **Target (`y`)**: The dependent variable — in this case, the `default` column, which indicates whether a borrower defaulted (1) or fully repaid (0) their loan.\n",
    "\n",
    "This separation is a fundamental step in any supervised machine learning workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5997f4fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1345310, 867), (1345310,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_encoded.drop('default', axis=1)  # All columns except the label\n",
    "y = df_encoded['default']               # The label (0 or 1)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6382948",
   "metadata": {},
   "source": [
    "## Exporting the Cleaned Dataset\n",
    "\n",
    "After completing preprocessing — including missing value imputation, feature encoding, and column filtering — we save the cleaned dataset as a CSV file. This step ensures reproducibility and allows us to use the same preprocessed data across multiple notebooks and models without repeating the cleaning steps.\n",
    "\n",
    "We exclude the index column from the saved file for clarity and compactness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3479af14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.to_csv('../data/cleaned_credit_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
